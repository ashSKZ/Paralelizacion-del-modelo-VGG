{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FY3iWCdZfSsR",
        "outputId": "88030913-1527-4e6e-dd6d-18116d1b0a0e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.4/105.4 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# Instalación de RAPIDS\n",
        "!pip install --upgrade --quiet \"cupy-cuda12x\"\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import time\n",
        "import gc\n",
        "\n",
        "# Configuración general\n",
        "DATA_DIR = \"/img/ImageNet/ILSVRC2012\"\n",
        "BATCH_SIZE = 500\n",
        "NUM_WORKERS = 4\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# Transformación estándar de ImageNet con salida 224x224\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Carga del dataset\n",
        "imagenet_dataset = datasets.ImageNet(root=DATA_DIR, split='train', transform=transform)\n",
        "data_loader = DataLoader(imagenet_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)\n",
        "\n",
        "def process_batch(images):\n",
        "    images = images.to(DEVICE, non_blocking=True)\n",
        "    _ = images.mean()\n",
        "    del images\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "\n",
        "def main():\n",
        "    total_images = len(imagenet_dataset)\n",
        "    print(f\"Procesando {total_images} imágenes en GPU por batches de {BATCH_SIZE}...\")\n",
        "\n",
        "    start_gpu = time.time()\n",
        "\n",
        "    for i, (images, _) in enumerate(data_loader):\n",
        "        process_batch(images)\n",
        "        if (i + 1) % 20 == 0:\n",
        "            print(f\"Batch {i + 1} procesado\")\n",
        "\n",
        "    torch.cuda.synchronize()\n",
        "    end_gpu = time.time()\n",
        "\n",
        "    tiempo_gpu = end_gpu - start_gpu\n",
        "    print(f\"\\nTiempo total GPU: {tiempo_gpu:.2f} segundos\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e_4e2bbJfdD4",
        "outputId": "a7b27f03-e6ea-4ce5-bd8d-7b0445e43681"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Procesando 1300000 imágenes en GPU por batches de 500...\n",
            "Batch 20/2600 procesado\n",
            "Batch 40/2600 procesado\n",
            "Batch 60/2600 procesado\n",
            "Batch 80/2600 procesado\n",
            "Batch 100/2600 procesado\n",
            "Batch 120/2600 procesado\n",
            "Batch 140/2600 procesado\n",
            "Batch 160/2600 procesado\n",
            "Batch 180/2600 procesado\n",
            "Batch 200/2600 procesado\n",
            "Batch 220/2600 procesado\n",
            "Batch 240/2600 procesado\n",
            "Batch 260/2600 procesado\n",
            "Batch 280/2600 procesado\n",
            "Batch 300/2600 procesado\n",
            "Batch 320/2600 procesado\n",
            "Batch 340/2600 procesado\n",
            "Batch 360/2600 procesado\n",
            "Batch 380/2600 procesado\n",
            "Batch 400/2600 procesado\n",
            "Batch 420/2600 procesado\n",
            "Batch 440/2600 procesado\n",
            "Batch 460/2600 procesado\n",
            "Batch 480/2600 procesado\n",
            "Batch 500/2600 procesado\n",
            "Batch 520/2600 procesado\n",
            "Batch 540/2600 procesado\n",
            "Batch 560/2600 procesado\n",
            "Batch 580/2600 procesado\n",
            "Batch 600/2600 procesado\n",
            "Batch 620/2600 procesado\n",
            "Batch 640/2600 procesado\n",
            "Batch 660/2600 procesado\n",
            "Batch 680/2600 procesado\n",
            "Batch 700/2600 procesado\n",
            "Batch 720/2600 procesado\n",
            "Batch 740/2600 procesado\n",
            "Batch 760/2600 procesado\n",
            "Batch 780/2600 procesado\n",
            "Batch 800/2600 procesado\n",
            "Batch 820/2600 procesado\n",
            "Batch 840/2600 procesado\n",
            "Batch 860/2600 procesado\n",
            "Batch 880/2600 procesado\n",
            "Batch 900/2600 procesado\n",
            "Batch 920/2600 procesado\n",
            "Batch 940/2600 procesado\n",
            "Batch 960/2600 procesado\n",
            "Batch 980/2600 procesado\n",
            "Batch 1000/2600 procesado\n",
            "Batch 1020/2600 procesado\n",
            "Batch 1040/2600 procesado\n",
            "Batch 1060/2600 procesado\n",
            "Batch 1080/2600 procesado\n",
            "Batch 1100/2600 procesado\n",
            "Batch 1120/2600 procesado\n",
            "Batch 1140/2600 procesado\n",
            "Batch 1160/2600 procesado\n",
            "Batch 1180/2600 procesado\n",
            "Batch 1200/2600 procesado\n",
            "Batch 1220/2600 procesado\n",
            "Batch 1240/2600 procesado\n",
            "Batch 1260/2600 procesado\n",
            "Batch 1280/2600 procesado\n",
            "Batch 1300/2600 procesado\n",
            "Batch 1320/2600 procesado\n",
            "Batch 1340/2600 procesado\n",
            "Batch 1360/2600 procesado\n",
            "Batch 1380/2600 procesado\n",
            "Batch 1400/2600 procesado\n",
            "Batch 1420/2600 procesado\n",
            "Batch 1440/2600 procesado\n",
            "Batch 1460/2600 procesado\n",
            "Batch 1480/2600 procesado\n",
            "Batch 1500/2600 procesado\n",
            "Batch 1520/2600 procesado\n",
            "Batch 1540/2600 procesado\n",
            "Batch 1560/2600 procesado\n",
            "Batch 1580/2600 procesado\n",
            "Batch 1600/2600 procesado\n",
            "Batch 1620/2600 procesado\n",
            "Batch 1640/2600 procesado\n",
            "Batch 1660/2600 procesado\n",
            "Batch 1680/2600 procesado\n",
            "Batch 1700/2600 procesado\n",
            "Batch 1720/2600 procesado\n",
            "Batch 1740/2600 procesado\n",
            "Batch 1760/2600 procesado\n",
            "Batch 1780/2600 procesado\n",
            "Batch 1800/2600 procesado\n",
            "Batch 1820/2600 procesado\n",
            "Batch 1840/2600 procesado\n",
            "Batch 1860/2600 procesado\n",
            "Batch 1880/2600 procesado\n",
            "Batch 1900/2600 procesado\n",
            "Batch 1920/2600 procesado\n",
            "Batch 1940/2600 procesado\n",
            "Batch 1960/2600 procesado\n",
            "Batch 1980/2600 procesado\n",
            "Batch 2000/2600 procesado\n",
            "Batch 2020/2600 procesado\n",
            "Batch 2040/2600 procesado\n",
            "Batch 2060/2600 procesado\n",
            "Batch 2080/2600 procesado\n",
            "Batch 2100/2600 procesado\n",
            "Batch 2120/2600 procesado\n",
            "Batch 2140/2600 procesado\n",
            "Batch 2160/2600 procesado\n",
            "Batch 2180/2600 procesado\n",
            "Batch 2200/2600 procesado\n",
            "Batch 2220/2600 procesado\n",
            "Batch 2240/2600 procesado\n",
            "Batch 2260/2600 procesado\n",
            "Batch 2280/2600 procesado\n",
            "Batch 2300/2600 procesado\n",
            "Batch 2320/2600 procesado\n",
            "Batch 2340/2600 procesado\n",
            "Batch 2360/2600 procesado\n",
            "Batch 2380/2600 procesado\n",
            "Batch 2400/2600 procesado\n",
            "Batch 2420/2600 procesado\n",
            "Batch 2440/2600 procesado\n",
            "Batch 2460/2600 procesado\n",
            "Batch 2480/2600 procesado\n",
            "Batch 2500/2600 procesado\n",
            "Batch 2520/2600 procesado\n",
            "Batch 2540/2600 procesado\n",
            "Batch 2560/2600 procesado\n",
            "Batch 2580/2600 procesado\n",
            "Batch 2600/2600 procesado\n",
            "\n",
            "Tiempo total GPU: 213.36 segundos\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import time\n",
        "import gc\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Configuración general\n",
        "DATA_DIR = \"/img/ImageNet/ILSVRC2012\"\n",
        "BATCH_SIZE_GPU = 500\n",
        "BATCH_SIZE_CPU = 1\n",
        "NUM_WORKERS = 4\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# Transformación\n",
        "imagenet_transform = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Dataset y dataloaders\n",
        "imagenet_dataset = datasets.ImageNet(root=DATA_DIR, split='train', transform=imagenet_transform)\n",
        "\n",
        "# DataLoader para CPU (batch de 1 imagen por iteración)\n",
        "cpu_loader = DataLoader(imagenet_dataset, batch_size=BATCH_SIZE_CPU, shuffle=False, num_workers=0)\n",
        "\n",
        "# DataLoader para GPU (batch grande por eficiencia)\n",
        "gpu_loader = DataLoader(imagenet_dataset, batch_size=BATCH_SIZE_GPU, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)\n",
        "\n",
        "#  CPU VERSION\n",
        "\n",
        "def cpu_preprocess():\n",
        "    print(\"\\n== Procesando en CPU ==\")\n",
        "    start_cpu = time.time()\n",
        "\n",
        "    for i, (img, _) in enumerate(cpu_loader):\n",
        "        img_np = img.squeeze(0).numpy()\n",
        "        _ = img_np.mean()\n",
        "        if (i + 1) % 200000 == 0:\n",
        "            print(f\"{i + 1}/{len(imagenet_dataset)} imágenes procesadas (CPU)\")\n",
        "\n",
        "    end_cpu = time.time()\n",
        "    tiempo_cpu = end_cpu - start_cpu\n",
        "    print(f\"Tiempo CPU: {tiempo_cpu:.2f} segundos\")\n",
        "    return tiempo_cpu\n",
        "\n",
        "\n",
        "def gpu_process_batch(images):\n",
        "    images = images.to(DEVICE, non_blocking=True)\n",
        "    _ = images.mean()\n",
        "    del images\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "\n",
        "def gpu_preprocess():\n",
        "    print(\"\\n== Procesando en GPU ==\")\n",
        "    start_gpu = time.time()\n",
        "\n",
        "    for i, (images, _) in enumerate(gpu_loader):\n",
        "        gpu_process_batch(images)\n",
        "        if (i + 1) % 20 == 0:\n",
        "            print(f\"Batch {i + 1} procesado\")\n",
        "\n",
        "    torch.cuda.synchronize()\n",
        "    end_gpu = time.time()\n",
        "    tiempo_gpu = end_gpu - start_gpu\n",
        "    print(f\"Tiempo GPU: {tiempo_gpu:.2f} segundos\")\n",
        "    return tiempo_gpu\n",
        "\n",
        "\n",
        "\n",
        "def main():\n",
        "    tiempo_cpu = cpu_preprocess()\n",
        "    tiempo_gpu = gpu_preprocess()\n",
        "\n",
        "    print(\"\\n== Benchmark final ==\")\n",
        "    print(f\"Tiempo CPU: {tiempo_cpu:.2f} s\")\n",
        "    print(f\"Tiempo GPU: {tiempo_gpu:.2f} s\")\n",
        "    print(f\"Speedup GPU vs CPU: {tiempo_cpu / tiempo_gpu:.2f}x\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "meZykoJcS82m",
        "outputId": "08156a88-40ee-46a9-f8e2-0c8a8e4a294c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "== Procesando en CPU ==\n",
            "200000/1300000 imágenes procesadas (CPU)\n",
            "400000/1300000 imágenes procesadas (CPU)\n",
            "600000/1300000 imágenes procesadas (CPU)\n",
            "800000/1300000 imágenes procesadas (CPU)\n",
            "1000000/1300000 imágenes procesadas (CPU)\n",
            "1200000/1300000 imágenes procesadas (CPU)\n",
            "Tiempo CPU: 809.11 segundos\n",
            "\n",
            "== Procesando en GPU ==\n",
            "Batch 20/2600 procesado\n",
            "Batch 40/2600 procesado\n",
            "Batch 60/2600 procesado\n",
            "Batch 80/2600 procesado\n",
            "Batch 100/2600 procesado\n",
            "Batch 120/2600 procesado\n",
            "Batch 140/2600 procesado\n",
            "Batch 160/2600 procesado\n",
            "Batch 180/2600 procesado\n",
            "Batch 200/2600 procesado\n",
            "Batch 220/2600 procesado\n",
            "Batch 240/2600 procesado\n",
            "Batch 260/2600 procesado\n",
            "Batch 280/2600 procesado\n",
            "Batch 300/2600 procesado\n",
            "Batch 320/2600 procesado\n",
            "Batch 340/2600 procesado\n",
            "Batch 360/2600 procesado\n",
            "Batch 380/2600 procesado\n",
            "Batch 400/2600 procesado\n",
            "Batch 420/2600 procesado\n",
            "Batch 440/2600 procesado\n",
            "Batch 460/2600 procesado\n",
            "Batch 480/2600 procesado\n",
            "Batch 500/2600 procesado\n",
            "Batch 520/2600 procesado\n",
            "Batch 540/2600 procesado\n",
            "Batch 560/2600 procesado\n",
            "Batch 580/2600 procesado\n",
            "Batch 600/2600 procesado\n",
            "Batch 620/2600 procesado\n",
            "Batch 640/2600 procesado\n",
            "Batch 660/2600 procesado\n",
            "Batch 680/2600 procesado\n",
            "Batch 700/2600 procesado\n",
            "Batch 720/2600 procesado\n",
            "Batch 740/2600 procesado\n",
            "Batch 760/2600 procesado\n",
            "Batch 780/2600 procesado\n",
            "Batch 800/2600 procesado\n",
            "Batch 820/2600 procesado\n",
            "Batch 840/2600 procesado\n",
            "Batch 860/2600 procesado\n",
            "Batch 880/2600 procesado\n",
            "Batch 900/2600 procesado\n",
            "Batch 920/2600 procesado\n",
            "Batch 940/2600 procesado\n",
            "Batch 960/2600 procesado\n",
            "Batch 980/2600 procesado\n",
            "Batch 1000/2600 procesado\n",
            "Batch 1020/2600 procesado\n",
            "Batch 1040/2600 procesado\n",
            "Batch 1060/2600 procesado\n",
            "Batch 1080/2600 procesado\n",
            "Batch 1100/2600 procesado\n",
            "Batch 1120/2600 procesado\n",
            "Batch 1140/2600 procesado\n",
            "Batch 1160/2600 procesado\n",
            "Batch 1180/2600 procesado\n",
            "Batch 1200/2600 procesado\n",
            "Batch 1220/2600 procesado\n",
            "Batch 1240/2600 procesado\n",
            "Batch 1260/2600 procesado\n",
            "Batch 1280/2600 procesado\n",
            "Batch 1300/2600 procesado\n",
            "Batch 1320/2600 procesado\n",
            "Batch 1340/2600 procesado\n",
            "Batch 1360/2600 procesado\n",
            "Batch 1380/2600 procesado\n",
            "Batch 1400/2600 procesado\n",
            "Batch 1420/2600 procesado\n",
            "Batch 1440/2600 procesado\n",
            "Batch 1460/2600 procesado\n",
            "Batch 1480/2600 procesado\n",
            "Batch 1500/2600 procesado\n",
            "Batch 1520/2600 procesado\n",
            "Batch 1540/2600 procesado\n",
            "Batch 1560/2600 procesado\n",
            "Batch 1580/2600 procesado\n",
            "Batch 1600/2600 procesado\n",
            "Batch 1620/2600 procesado\n",
            "Batch 1640/2600 procesado\n",
            "Batch 1660/2600 procesado\n",
            "Batch 1680/2600 procesado\n",
            "Batch 1700/2600 procesado\n",
            "Batch 1720/2600 procesado\n",
            "Batch 1740/2600 procesado\n",
            "Batch 1760/2600 procesado\n",
            "Batch 1780/2600 procesado\n",
            "Batch 1800/2600 procesado\n",
            "Batch 1820/2600 procesado\n",
            "Batch 1840/2600 procesado\n",
            "Batch 1860/2600 procesado\n",
            "Batch 1880/2600 procesado\n",
            "Batch 1900/2600 procesado\n",
            "Batch 1920/2600 procesado\n",
            "Batch 1940/2600 procesado\n",
            "Batch 1960/2600 procesado\n",
            "Batch 1980/2600 procesado\n",
            "Batch 2000/2600 procesado\n",
            "Batch 2020/2600 procesado\n",
            "Batch 2040/2600 procesado\n",
            "Batch 2060/2600 procesado\n",
            "Batch 2080/2600 procesado\n",
            "Batch 2100/2600 procesado\n",
            "Batch 2120/2600 procesado\n",
            "Batch 2140/2600 procesado\n",
            "Batch 2160/2600 procesado\n",
            "Batch 2180/2600 procesado\n",
            "Batch 2200/2600 procesado\n",
            "Batch 2220/2600 procesado\n",
            "Batch 2240/2600 procesado\n",
            "Batch 2260/2600 procesado\n",
            "Batch 2280/2600 procesado\n",
            "Batch 2300/2600 procesado\n",
            "Batch 2320/2600 procesado\n",
            "Batch 2340/2600 procesado\n",
            "Batch 2360/2600 procesado\n",
            "Batch 2380/2600 procesado\n",
            "Batch 2400/2600 procesado\n",
            "Batch 2420/2600 procesado\n",
            "Batch 2440/2600 procesado\n",
            "Batch 2460/2600 procesado\n",
            "Batch 2480/2600 procesado\n",
            "Batch 2500/2600 procesado\n",
            "Batch 2520/2600 procesado\n",
            "Batch 2540/2600 procesado\n",
            "Batch 2560/2600 procesado\n",
            "Batch 2580/2600 procesado\n",
            "Batch 2600/2600 procesado\n",
            "Tiempo GPU: 222.10 segundos\n",
            "\n",
            "== Benchmark final ==\n",
            "Tiempo CPU: 809.11 s\n",
            "Tiempo GPU: 222.10 s\n",
            "Speedup GPU vs CPU: 3.64x\n"
          ]
        }
      ]
    }
  ]
}